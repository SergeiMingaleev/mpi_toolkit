#------------------------------------------------------------------
# Пример 7.1: Параллельное решение трёхдиагональной системы
#             линейных уравнений методом прогонки.
#
# Задача: найти вектор x, являющийся решением системы линейных
#         уравнений A*x = d с трёхдиагональной матрицей A,
#         максимально эффективно параллелизуя работу между
#         процессами с использованием MPI интерфейса.
#
# При параллелизации этого алгоритма мы будем считать, что общее
# число MPI процессов равно P.
# При этом процесс 0 будет занят одновременно и синхронизацией
# данных между процессами, и реальной работой - то есть, все P
# процессов будут "рабочими".
#
# Размер матрицы A равен (N, N), но ненулевыми являются только
# три главные диагонали, которые задаются тремя векторами:
# a (для верхней диагонали), b (для главной диагонали),
# и c (для нижней диагонали). Реально вектор b имеет N элементов,
# а векторы a и c оба имеют N-1 элементов - но для простоты
# мы будем выделять память в N элементов для каждого вектора.
# Считая, что N = P * K + L, где K и L - это целые числа,
# причём 0 <= L <= P-1, мы будем держать на каждом процессе
# либо по K+1 либо по К элементов каждого вектора, для
# максимальной балансировки памяти и вычислений по всем процессам.
#
# Точно так же будут разбиты на кусочки по процессам и
# векторы x и d (которые оба также состоят из N элементов).

# Реализация последовательного метода прогонки вынесена
# в функцию `consecutive_tridiagonal_matrix_algorithm()`,
# а реализация параллельного метода прогонки вынесена
# в функцию `parallel_tridiagonal_matrix_algorithm()`.
# Остальная часть кода занимается подготовкой и пересылкой
# данных между MPI процессами.
#
#------------------------------------------------------------------
# Этот пример (в его оригинальном виде) детально обсуждается
# в лекции Д.В. Лукьяненко "7. Параллельный вариант метода прогонки":
# https://youtu.be/CrqeCy-dZQI?list=PLcsjsqLLSfNCxGJjuYNZRzeDIFQDQ9WvC
#
# Данная программа объединяет в себе оба примера Д.В. Лукьяненко из
# его файлов "Example-7-1.py" (для вещественных чисел) и
# "Example-7-1-complex.py" (для комплексных чисел).
#------------------------------------------------------------------

import sys
from mpi4py import MPI
import numpy as np


#------------------------------------------------------------------
def consecutive_tridiagonal_matrix_algorithm(a, b, c, d):
    """
    Реализация последовательного метода прогонки для решения
    системы линейных уравнений A*x = d с трёхдиагональной
    матрицей `A` размером NxN. Такая матрица определяется тремя
    векторами: вектором `b` (с размером N), задающим главную
    диагональ матрицы, и векторами `a` и `c` (с размером N-1),
    задающими нижнюю и верхнюю кодиагонали, соответственно.

    Для удобства реализации, мы ожидаем, что векторы `a` и `c`
    придут также с размером N, но при этом элементы `a[0]`
    и `c[N-1]` просто не будут использоваться.

    Детали алгоритма метода прогонки описаны на странице:
    https://ru.wikipedia.org/wiki/Метод_прогонки
    Такая реализация метода прогонки требует `8*N-7`
    арифметических операций.

    :param a: Вектор, задающий нижнюю кодиагональ матрицы `A`.
    :param b: Вектор, задающий главную диагональ матрицы `A`.
    :param c: Вектор, задающий верхнюю кодиагональ матрицы `A`.
    :param d: Вектор `d`, задающий правую часть уравнения.
    :return: Вектор решения `x`.
    """
    N = len(d)
    x = np.empty(N, dtype=datatype)

    # Прямой ход метода прогонки (зануляем нижнюю кодиагональ `a`):
    for n in range(1, N):
        coef = a[n] / b[n-1]
        b[n] -= coef * c[n-1]
        d[n] -= coef * d[n-1]

    # Обратный ход метода прогонки (находим `x`, эффективно зануляя
    # верхнюю кодиагональ `c`):
    x[N-1] = d[N-1] / b[N-1]
    for n in range(N-2, -1, -1):
        x[n] = (d[n] - c[n] * x[n+1])/b[n]

    return x


#------------------------------------------------------------------
def parallel_tridiagonal_matrix_algorithm(a_part, b_part, c_part, d_part):
    """
    Реализация параллельного метода прогонки для решения
    системы линейных уравнений A*x = d с трёхдиагональной
    матрицей `A` размером NxN. Такая матрица определяется тремя
    векторами: вектором `b` (с размером N), задающим главную
    диагональ матрицы, и векторами `a` и `c` (с размером N-1),
    задающими нижнюю и верхнюю кодиагонали, соответственно.

    Для удобства реализации, мы ожидаем, что полные векторы
    `a` и `c` придут также с размером N, но при этом элементы
    `a[0]` и `c[N-1]` просто не будут использоваться.

    Мы также ожидаем, что эта функция была вызвана каждым из
    MPI процессов, и каждый процесс работает со своими
    кусочками `a_part`, `b_part`, `c_part`, и `d_part`
    векторов `a`, `b`, `c`, и `d`.

    :param a_part: Часть вектора `a`, задающая на данном процессе
                   свой кусочек нижней кодиагонали матрицы `A`.
    :param b_part: Часть вектора `b`, задающая на данном процессе
                   свой кусочек главной диагонали матрицы `A`.
    :param c_part: Часть вектора `c`, задающая на данном процессе
                   свой кусочек верхней кодиагонали матрицы `A`.
    :param d_part: Часть вектора `d`, задающая на данном процессе
                   свой кусочек правой части уравнения.
    :return: Часть `x_part` точного решения `x` уравнения A*x=d.
             Окончательное решение в виде полного вектора `x` должно
             быть собрано за пределами этой функции.
    """
    N_part = len(d_part)

    # Прямой ход метода прогонки (зануляем нижнюю
    # кодиагональ `a_part`, кроме колонки элементов для `n=0`,
    # которую мы всю записываем обратно в вектор `a_part`
    # для экономии памяти):
    for n in range(1, N_part):
        coef = a_part[n] / b_part[n-1]
        a_part[n] = -coef * a_part[n-1]
        b_part[n] -= coef * c_part[n-1]
        d_part[n] -= coef * d_part[n-1]

    # Обратный ход метода прогонки (зануляем верхнюю
    # кодиагональ `c_part`, кроме колонки элементов для
    # `n=N_part-1`, которую мы всю записываем обратно
    # в вектор `с_part` для экономии памяти).
    # При этом ненулевые элементы в `a_part`,
    # соответствующие колонке n=0, изменятся ещё раз:
    for n in range(N_part-3, -1, -1):
        coef = c_part[n] / b_part[n+1]
        c_part[n] = -coef * c_part[n+1]
        a_part[n] -= coef * a_part[n+1]
        d_part[n] -= coef * d_part[n+1]

    # На этом этапе у нас остаются (на каждом процессе)
    # ненулевыми элементы на главной диагонали (их значения
    # расположены в векторе `b_part`), в колонке `n=0`
    # (их значения расположены в векторе `a_part`), и в
    # колонке `n=N_part-1` (их значения расположены
    # в векторе `c_part[:N_part-1]`). Наконец, на каждом процессе,
    # кроме последнего, остаётся ещё один ненулевой элемент
    # `c_part[N_part-1]`, расположенный в самом низу колонки `n=N_part`.
    # От этого последнего элемента хочется избавиться в первую
    # очередь - но для этого нужно вычесть из последней строки
    # первых P-1 процессов нулевую строку (домноженную на нужный
    # коэффициент) следующего процесса. Для этого каждый процесс
    # (кроме первого) должен послать элементы своей нулевой строки
    # предыдущему процессу (https://youtu.be/CrqeCy-dZQI?t=1499):

    if rank > 0:
        temp_array_send = np.array([a_part[0], b_part[0],
                                    c_part[0], d_part[0]],
                                   dtype=datatype)
    if rank < P-1:
        temp_array_recv = np.empty(4, dtype=datatype)

    if rank == 0:
        comm.Recv([temp_array_recv, 4, MPI_datatype],
                  source=1, tag=0, status=None)
    if rank in range(1, P-1):
        comm.Sendrecv(sendbuf=[temp_array_send, 4, MPI_datatype],
                      dest=rank-1, sendtag=0,
                      recvbuf=[temp_array_recv, 4, MPI_datatype],
                      source=rank+1, recvtag=MPI.ANY_TAG, status=None)
    if rank == P-1:
        comm.Send([temp_array_send, 4, MPI_datatype], dest=P-2, tag=0)

    # Теперь мы готовы обнулить этот ненулевой элемент
    # `c_part[-1]` (что требуется на каждом процессе, кроме
    # последнего):

    if rank < P-1:
        a_N_part, b_N_part, c_N_part, d_N_part = temp_array_recv
        coef = c_part[N_part-1] / b_N_part
        # Последние элементы `b_part` и `d_part` просто обновят
        # свои значения:
        b_part[N_part-1] -= coef * a_N_part
        d_part[N_part-1] -= coef * d_N_part
        # А последний элемент вектора `c_part` полностью обнулится -
        # но на его место в памяти мы запишем значение нового
        # ненулевого элемента, который появится при этом
        # в колонке `n=N_part` в нумерации следующего процесса
        # (https://youtu.be/CrqeCy-dZQI?t=1604):
        c_part[N_part-1] = -coef * c_N_part

    # Важно, что теперь последние элементы векторов `a_part`, `b_part`,
    # `c_part`, и `d_part` на каждом процессе (включая и последний!)
    # совместно образуют новую трёхдиагональную матрицу с размером,
    # равным `P` (что намного меньше изначального `N`!) - соберём
    # вместе на процессе 0 элементы этой новой матрицы и соответствующие
    # им последние элементы вектора `d_part` в массиве `A_extended`:

    temp_array_send = np.array([a_part[N_part-1], b_part[N_part-1],
                                c_part[N_part-1], d_part[N_part-1]],
                               dtype=datatype)

    if rank == 0:
        A_extended = np.empty((P, 4), dtype=datatype)
    else:
        A_extended = None

    comm.Gather([temp_array_send, 4, MPI_datatype],
                [A_extended, 4, MPI_datatype], root=0)

    # И решим это небольшое уравнение на процессе 0, используя
    # последовательный метод прогонки - это потребует всего
    # `8*P-7` арифметических операций:
    if rank == 0:
        x_temp = consecutive_tridiagonal_matrix_algorithm(
            A_extended[:,0], A_extended[:,1], A_extended[:,2], A_extended[:,3])
    else:
        x_temp = None

    # Найденное решение делает теперь известными последние элементы
    # в векторах `x_part` на каждом процессе - отдадим их значения
    # назад на соответствующие процессы. При этом процессу 0 достаточно
    # отдать только одно значение (поскольку у него кодиагональ,
    # описываемая вектором `a_part`, полностью зануляется), а всем
    # остальным процессам (у которых остался столбец с ненулевыми
    # `a_part`) нужно будет отдать по два значения
    # (https://youtu.be/CrqeCy-dZQI?t=2017).

    # Как обычно, введём два списка, `rcounts_temp` (список размеров)
    # и `displs_temp` (список смещений), для описания логики распределения
    # найденного решения `x_part` между процессами:
    if rank == 0:
        # Сделаем такой анализ только на процессе 0:
        rcounts_temp = np.empty(P, dtype=np.int32)
        displs_temp = np.empty(P, dtype=np.int32)
        # Процессу 0 отдаём только одно (самое первое)
        # значение из найденного вектора решения `x_temp`:
        rcounts_temp[0] = 1
        displs_temp[0] = 0
        for k in range(1, P):
            # Остальным процессам отдаём по два таких значения
            # `x_temp[i]` так, чтобы процесс 1 получил значения
            # для i=0,1, процесс 2 получил значения для i=1,2
            # и так далее:
            rcounts_temp[k] = 2
            displs_temp[k] = k - 1
    else:
        # На остальных процессах эти списки используются только
        # в качестве пустых заглушек (в вызове `Scatterv` ниже):
        rcounts_temp = None
        displs_temp = None

    # Разбросаем теперь решение `x_temp` по всем процессам согласно
    # вышеописанной схеме:
    if rank == 0:
        x_part_last = np.empty(1, dtype=datatype)
        comm.Scatterv([x_temp, rcounts_temp, displs_temp, MPI_datatype],
                      [x_part_last, 1, MPI_datatype], root=0)
    else:
        x_part_last = np.empty(2, dtype=datatype)
        comm.Scatterv([x_temp, rcounts_temp, displs_temp, MPI_datatype],
                      [x_part_last, 2, MPI_datatype], root=0)

    # Наконец мы знаем на каждом процессе нужные ему одно или
    # два значения из найденного вектора решения `x_temp`.
    # Зная их, мы можем теперь рекурсивно (и снова параллельно
    # на всех процессах) найти все остальные элементы нужного
    # нам решения (https://youtu.be/CrqeCy-dZQI?t=2017).

    # Будем записывать это решение в вектор `x_part`:
    x_part = np.empty(N_part, dtype=datatype)

    if rank == 0:
        # На процессе 0 мы получили одно значение решения
        # `x_temp` - и оно соответствует последнему элементу
        # вектора решения `x_part`:
        x_part[N_part-1] = x_part_last[0]
        # Все же остальные элементы находятся из него:
        for n in range(N_part-1):
            x_part[n] = (d_part[n] - c_part[n]*x_part_last[0])/b_part[n]
    else:
        # На остальных процессах мы получили по два значения
        # решения `x_temp` - второе из них соответствует
        # последнему элементу вектора решения `x_part`:
        x_part[N_part-1] = x_part_last[1]
        # Все же остальные элементы находятся из обоих полученных
        # значений:
        for n in range(N_part-1):
            x_part[n] = (d_part[n] - a_part[n]*x_part_last[0] -
                         c_part[n]*x_part_last[1]) / b_part[n]

    return x_part


#------------------------------------------------------------------
def diagonals_preparation(N_part):
    """
    Функция задает в качестве элементов диагоналей
    трёхдиагональной матрицы `A` случайные числа.

    :param N_part: Число элементов в требуемых векторах.
    :return: Векторы диагоналей `a`, `b`, `c`.
    """
    a = np.empty(N_part, dtype=datatype)
    b = np.empty(N_part, dtype=datatype)
    c = np.empty(N_part, dtype=datatype)
    for n in range(N_part):
        if is_complex_version:
            a[n] = np.random.random_sample() + np.random.random_sample()*1j
            b[n] = np.random.random_sample() + np.random.random_sample()*1j
            c[n] = np.random.random_sample() + np.random.random_sample()*1j
        else:
            a[n] = np.random.random_sample()
            b[n] = np.random.random_sample()
            c[n] = np.random.random_sample()
    return a, b, c


#------------------------------------------------------------------
def auxiliary_arrays_determination(M, P):
    """
    Расчёт списков числа элементов `rcounts` и соответствующих
    смещений "displs", определяющих распределение больших матриц
    и векторов по всем процессам MPI коммуникатора, включая
    и процесс 0.

    :param M: Общее число элементов вдоль нужной оси матрицы.
    :param P: Общее число процессов вдоль нужной оси сетки процессов,
              работающих над параллелизацией вычислений.
    :return: Рассчитанные списки числа элементов `rcounts` и
             соответствующих смещений "displs", определяющие
             передачу данных каждому процессу.
    """
    # Считая, что M = P * K + L, где K и L - это целые числа,
    # причём 0 <= L <= P-1, мы можем держать на каждом процессе
    # либо по K+1 либо по К элементов, для максимальной балансировки
    # памяти и вычислений по всем "рабочим" процессам.
    # Найдём целые числа K и L из описания алгоритма выше:
    K, L = divmod(np.int32(M), P)

    # Введём два новых списка для описания того, как именно
    # матрицы и векторы будут распределяться по всем процессам.
    # Здесь `rcounts` будет содержать число элементов, хранимое
    # каждым процессом (это K+1 для первых L процессов,
    # и K для оставшихся процессов).
    # Другой список `displs` будет содержать индекс смещений
    # - то есть, номер первой строки, начиная с которой будут
    # храниться `rcounts[m]` строк на процессе `m`.
    # При этом мы предполагаем, что все элементы, которые
    # хранятся на каждом процессе, идут подряд.
    rcounts = np.empty(P, dtype=np.int32)
    displs = np.empty(P, dtype=np.int32)

    # Цикл по всем процессам (они все "рабочие"):
    for m in range(0, P):
        if m < L:
            # Процессы от 0 до L-1 содержат по K+1 элементов
            # (если L=0, то таких процессов не будет!):
            rcounts[m] = K + 1
        else:
            # Оставшиеся процессы от L до P-1 содержат по K элементов:
            rcounts[m] = K
        # Индекс смещений равен 0 для процесса 0 и сдвигается
        # для каждого следующего процесса на число элементов,
        # хранимых в предыдущем процессе:
        if m == 0:
            displs[m] = 0
        else:
            displs[m] = displs[m - 1] + rcounts[m - 1]
    return rcounts, displs


#------------------------------------------------------------------
# Начинаем выполнение программы - первым делом, настроим MPI:
#------------------------------------------------------------------

# Работаем с коммуникатором по всем доступным процессам:
comm = MPI.COMM_WORLD

# Число P доступных процессов в этом коммуникаторе:
P = comm.Get_size()

# Номер текущего процесса (от 0 до P-1):
rank = comm.Get_rank()

# Для удобства тестирования, пусть версия программы для комплексных
# чисел запускается при добавлении к программе аргумента 'complex':
# (mpiexec -n 4 python.exe Example-07-1.py complex)
is_complex_version = False
if len(sys.argv) == 2 and sys.argv[1] == 'complex':
    is_complex_version = True

if is_complex_version:
    datatype = np.complex128
    MPI_datatype = MPI.DOUBLE_COMPLEX
else:
    datatype = np.float64
    MPI_datatype = MPI.DOUBLE

# Определяем N - число элементов в векторе `x`:
N = 30

# Разберёмся, как именно `N` элементов вектора должны разбиться
# на кусочки - посчитаем для этого списки числа элементов `rcounts`
# и их смещений `displs`:
if rank == 0:
    # Сделаем такой анализ только на процессе 0.
    # Всю логику расчёта этих списков мы перенесём в отдельную
    # функцию `auxiliary_arrays_determination()`, определённую
    # выше в этом файле:
    rcounts, displs = auxiliary_arrays_determination(N, P)
else:
    # На остальных процессах эти списки используются только
    # в качестве пустых заглушек (в нескольких `Scatter` ниже):
    rcounts = None
    displs = None

# Подготовим "хранилища" для `N_part` и `displ` на всех процессах:
N_part = np.array(0, dtype=np.int32)
displ = np.array(0, dtype=np.int32)

# Разбросаем теперь списоки `rcounts` и `displs` по всем процессам
# в виде отдельных значений, нужных каждому конкретному процессу:
comm.Scatter([rcounts, 1, MPI.INT],
             [N_part, 1, MPI.INT], root=0)
comm.Scatter([displs, 1, MPI.INT],
             [displ, 1, MPI.INT], root=0)

# Формируем на каждом MPI процессе свои кусочки диагоналей:
codiagonal_down_part, diagonal_part, codiagonal_up_part = diagonals_preparation(N_part)

# Задаём тестовое решение `x`, элементами которого является
# последовательность натуральных чисел от 1 до N включительно:
if rank == 0:
    x = np.array(range(1, N+1), dtype=np.float64)
else:
    x = np.empty(N, dtype=np.float64)

# Передаём вектор `x` всем MPI процессам:
comm.Bcast([x, N, MPI.DOUBLE], root=0)

# Умножаем матрицу `А` на вектор `x`, чтобы получить
# соответствующую этому решению модельную правую часть
# вектора `d`. Сразу же будем распределять его по всем
# MPI процессам по кусочкам `d_part`:
d_part = np.zeros(N_part, dtype=datatype)
for n in range(N_part):
    if rank == 0 and n == 0:
        d_part[n] = (diagonal_part[n]*x[displ+n] +
                     codiagonal_up_part[n]*x[displ+n+1])
    elif rank == P-1 and n == N_part-1:
        d_part[n] = (codiagonal_down_part[n]*x[displ+n-1] +
                     diagonal_part[n]*x[displ+n])
    else:
        d_part[n] = (codiagonal_down_part[n]*x[displ+n-1] +
                     diagonal_part[n]*x[displ+n] +
                     codiagonal_up_part[n]*x[displ+n+1])

# Для сформированной матрицы `А` и модельной правой части `d`
# запускаем реализованный нами параллельный алгоритм решения
# СЛАУ с трёхдиагональной матрицей:
x_part = parallel_tridiagonal_matrix_algorithm(codiagonal_down_part,
                                               diagonal_part,
                                               codiagonal_up_part,
                                               d_part)

# Выводим результат и убеждаемся, что на каждом MPI процессе
# результат вычислений совпадает с кусочком требуемого решения:
print(f'For rank={rank}:')

if np.iscomplexobj(x_part):
    print(f'   x_part.real = {x_part.real}')
    # x_part_imag_formatted = [f"{x:.3g}" for x in x_part.imag]
    # print(f'   x_part.imag = {x_part_imag_formatted}')
    # You can also define a custom formatter function using
    # an f-string and pass it to set_printoptions:
    float_formatter = "{:.3g}".format
    np.set_printoptions(formatter={'float_kind': float_formatter})
    print(f'   x_part.imag = {x_part.imag}')
else:
    print(f'   x_part = {x_part}')
print()

#------------------------------------------------------------------
